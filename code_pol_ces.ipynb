{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('polish_czech_train.csv')\n",
    "test_df = pd.read_csv('polish_czech_test.csv')\n",
    "\n",
    "\n",
    "def ngrams(df, n):\n",
    "    ngram_counts = {'pol': {}, 'ces': {}}\n",
    "    for i, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "\n",
    "            if ngram in ngram_counts[lan]:\n",
    "                ngram_counts[lan][ngram] += 1\n",
    "\n",
    "            else:\n",
    "                ngram_counts[lan][ngram] = 1\n",
    "    return ngram_counts['pol'], ngram_counts['ces']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify(df, n, ngrams_pol, ngrams_ces):\n",
    "    df['predicted_lang'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['pol_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['ces_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "\n",
    "    for index, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        count_pol = 0\n",
    "        zero_ces = 0\n",
    "        zero_pol = 0\n",
    "\n",
    "        count_ces = 0\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "            if ngram not in ngrams_pol:\n",
    "                count_ces += 1\n",
    "            elif ngram not in ngrams_ces:\n",
    "                count_pol += 1\n",
    "            elif ngrams_pol[ngram] < ngrams_ces[ngram]:\n",
    "                count_ces += 1\n",
    "            else:\n",
    "                count_pol += 1\n",
    "        if count_pol >= count_ces:\n",
    "            df.at[index, 'predicted_lang'] = 'pol'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "\n",
    "        else:\n",
    "            df.at[index, 'predicted_lang'] = 'ces'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "polish_ngrams, czech_ngrams = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n",
    "for i in range(1, 5):\n",
    "    polish_ngrams[i], czech_ngrams[i] = ngrams(train_df, i)\n",
    "\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "    ngramsp = json.dumps(polish_ngrams[i])\n",
    "    ngramsc = json.dumps(czech_ngrams[i])\n",
    "\n",
    "\n",
    "    # You can also save the JSON to a file\n",
    "    with open(f'polish_{i}grams.json', 'w') as json_file:\n",
    "        json.dump(ngramsp, json_file)\n",
    "    with open(f'czech_{i}grams.json', 'w') as json_file:\n",
    "        json.dump(ngramsc, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1, 5):\n",
    "    classified_df = classify(test_df, i, polish_ngrams[i], czech_ngrams[i])\n",
    "    classified_df.to_csv(f'classified_without_normalisation_using_{i}_gram.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50932 93437\n"
     ]
    }
   ],
   "source": [
    "count_pol = (train_df['lan_code'] == 'pol').sum()\n",
    "count_ces = (train_df['lan_code'] == 'ces').sum()\n",
    "print(count_ces, count_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total ngrams is: 3084568 1430566\n",
      "The total ngrams is: 2991131 1379634\n",
      "The total ngrams is: 2897694 1328702\n",
      "The total ngrams is: 2804257 1277770\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    total_sump = sum(polish_ngrams[i].values())\n",
    "    total_sumc= sum(czech_ngrams[i].values())\n",
    "\n",
    "    print(\"The total ngrams is:\", total_sump, total_sumc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_ngrams_normalised = [0, 0, 0, 0, 0]\n",
    "for i in range(1,5):\n",
    "    polish_ngrams_normalised[i] = polish_ngrams[i].copy()\n",
    "    sum_dict1 = sum(polish_ngrams[i].values())\n",
    "    sum_dict2 = sum(czech_ngrams[i].values())\n",
    "\n",
    "    scaling_factor = sum_dict1 / sum_dict2\n",
    "\n",
    "    for key in polish_ngrams[i]:\n",
    "        polish_ngrams_normalised[i][key] /= scaling_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    classified_df = classify(test_df, i, polish_ngrams_normalised[i], czech_ngrams[i])\n",
    "    classified_df.to_csv(f'classified_using_{i}_gram.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1gram & 0.7700569739789548 & 0.6415094339622641 \\\\ \n",
      "2gram & 0.7998873629680612 & 0.7091125703044912 \\\\ \n",
      "3gram & 0.9474497866365013 & 0.9427866899398776 \\\\ \n",
      "4gram & 0.987616706384878 & 0.9874213836477987 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    classified_df = pd.read_csv(f'classified_without_normalisation_using_{i}_gram.csv')\n",
    "\n",
    "    true = (list(classified_df['lan_code']))\n",
    "    pred = (list(classified_df['predicted_lang']))\n",
    "\n",
    "\n",
    "    print(f\"{i}gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1gram & 0.7959109657652166 & 0.5372509904967723 \\\\ \n",
      "2gram & 0.9794780573595491 & 0.9793865846563046 \\\\ \n",
      "3gram & 0.9925201476894107 & 0.9925193250768847 \\\\ \n",
      "4gram & 0.996046220186964 & 0.9960380129110908 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "precision_pol = [0,0,0,0,0]\n",
    "recall_pol = [0,0,0,0,0]\n",
    "precision_ces = [0,0,0,0,0]\n",
    "recall_ces = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    classified_df = pd.read_csv(f'classified_using_{i}_gram.csv')\n",
    "\n",
    "    true = (list(classified_df['lan_code']))\n",
    "    pred = (list(classified_df['predicted_lang']))\n",
    "    # TP = len(classified_df[(classified_df['lan_code'] == 'pol') & (classified_df['predicted_lang'] == 'pol')])\n",
    "    # TN = len(classified_df[(classified_df['lan_code'] != 'pol') & (classified_df['predicted_lang'] != 'pol')])\n",
    "    # FP = len(classified_df[(classified_df['lan_code'] != 'pol') & (classified_df['predicted_lang'] == 'pol')])\n",
    "    # FN = len(classified_df[(classified_df['lan_code'] == 'pol') & (classified_df['predicted_lang'] != 'pol')])\n",
    "\n",
    "    # # Calculate precision and recall\n",
    "    # precision_pol[i] = TP / (TP + FP) \n",
    "    # recall_pol[i] = TP / (TP + FN) \n",
    "\n",
    "    # print(TP,FP, TN,FN, precision_pol[i], recall_pol[i])\n",
    "    # TP = len(classified_df[(classified_df['lan_code'] == 'ces') & (classified_df['predicted_lang'] == 'ces')])\n",
    "    # TN = len(classified_df[(classified_df['lan_code'] != 'ces') & (classified_df['predicted_lang'] != 'ces')])\n",
    "    # FP = len(classified_df[(classified_df['lan_code'] != 'ces') & (classified_df['predicted_lang'] == 'ces')])\n",
    "    # FN = len(classified_df[(classified_df['lan_code'] == 'ces') & (classified_df['predicted_lang'] != 'ces')])\n",
    "\n",
    "    # precision_ces[i] = TP / (TP + FP) \n",
    "    # recall_ces[i] = TP / (TP + FN) \n",
    "    # print((TP+TN)/(TP+TN+FP+FN))\n",
    "    print(f\"{i}gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n",
    "\n",
    "    result[i] = classified_df[(classified_df['lan_code'] != classified_df['predicted_lang'])]\n",
    "    # compare(result[i],i, polish_ngrams_normalised[i], czech_ngrams[i]\n",
    "    # print(result[i]['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_zero(df, n, ngrams_pol, ngrams_ces):\n",
    "    df['predicted_lang'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['pol_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['ces_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "\n",
    "    for index, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        count_pol = 0\n",
    "        zero_ces = 0\n",
    "        zero_pol = 0\n",
    "\n",
    "        count_ces = 0\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "            if ngram not in ngrams_pol:\n",
    "                zero_ces+=1\n",
    "                count_ces += 1\n",
    "            elif ngram not in ngrams_ces:\n",
    "                zero_pol+=1\n",
    "                count_pol += 1\n",
    "            elif ngrams_pol[ngram] < ngrams_ces[ngram]:\n",
    "                count_ces += 1\n",
    "            else:\n",
    "                count_pol += 1\n",
    "        if zero_ces > 0:\n",
    "            df.at[index, 'predicted_lang'] = 'ces'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "\n",
    "        elif zero_pol > 0:\n",
    "            \n",
    "            df.at[index, 'predicted_lang'] = 'pol'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "        elif count_pol >= count_ces:\n",
    "            df.at[index, 'predicted_lang'] = 'pol'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "\n",
    "        else:\n",
    "            df.at[index, 'predicted_lang'] = 'ces'\n",
    "            df.at[index, 'pol_count'] = count_pol\n",
    "            df.at[index, 'ces_count'] = count_ces\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    classified_df = classify_zero(test_df, i, polish_ngrams_normalised[i], czech_ngrams[i])\n",
    "    classified_df.to_csv(f'classified_using_{i}_gram_zero_handled.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1gram & 0.9354931908409589 & 0.92170226913806 \\\\ \n",
      "2gram & 0.9888574712390337 & 0.9887512814119082 \\\\ \n",
      "3gram & 0.9801764721324643 & 0.9792757598426287 \\\\ \n",
      "4gram & 0.9362192278119122 & 0.922699692461142 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    classified_df = pd.read_csv(f'classified_using_{i}_gram_zero_handled.csv')\n",
    "\n",
    "    true = (list(classified_df['lan_code']))\n",
    "    pred = (list(classified_df['predicted_lang']))\n",
    "\n",
    "\n",
    "    print(f\"{i}gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
