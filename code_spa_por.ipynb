{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('spanish_portugese_train.csv')\n",
    "test_df = pd.read_csv('spanish_portugese_test.csv')\n",
    "\n",
    "\n",
    "def ngrams(df, n):\n",
    "    ngram_counts = {'spa': {}, 'por': {}}\n",
    "    for i, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "\n",
    "            if ngram in ngram_counts[lan]:\n",
    "                ngram_counts[lan][ngram] += 1\n",
    "\n",
    "            else:\n",
    "                ngram_counts[lan][ngram] = 1\n",
    "    return ngram_counts['spa'], ngram_counts['por']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify(df, n, ngrams_spa, ngrams_por):\n",
    "    df['predicted_lang'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['spa_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['por_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "\n",
    "    for index, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        count_spa = 0\n",
    "\n",
    "        count_por = 0\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "            if ngram not in ngrams_spa:\n",
    "                count_por += 1\n",
    "            elif ngram not in ngrams_por:\n",
    "                count_spa += 1\n",
    "            elif ngrams_spa[ngram] < ngrams_por[ngram]:\n",
    "                count_por += 1\n",
    "            else:\n",
    "                count_spa += 1\n",
    "        if count_spa >= count_por:\n",
    "            df.at[index, 'predicted_lang'] = 'spa'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "\n",
    "        else:\n",
    "            df.at[index, 'predicted_lang'] = 'por'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "spaish_ngrams, czech_ngrams = [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]\n",
    "for i in range(1, 5):\n",
    "    spaish_ngrams[i], czech_ngrams[i] = ngrams(train_df, i)\n",
    "\n",
    "\n",
    "    ngramsp = json.dumps(spaish_ngrams[i])\n",
    "    ngramsc = json.dumps(czech_ngrams[i])\n",
    "\n",
    "\n",
    "    with open(f'spaish_{i}grams.json', 'w') as json_file:\n",
    "        json.dump(ngramsp, json_file)\n",
    "    with open(f'czech_{i}grams.json', 'w') as json_file:\n",
    "        json.dump(ngramsc, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1, 5):\n",
    "    with open(f'spaish_{i}grams.json', 'r') as json_file:\n",
    "        spaish_ngramss = json.load(ngramsp, json_file)\n",
    "    with open(f'czech_{i}grams.json', 'r') as json_file:\n",
    "        czech_ngramss = json.load(ngramsc, json_file)\n",
    "    spclassified_df = classify(test_df, i, spaish_ngrams[i], czech_ngrams[i])\n",
    "    # spclassified_df.to_csv(f'spclassified_without_normalisation_using_{i}_gram.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318760 295536\n"
     ]
    }
   ],
   "source": [
    "count_spa = (train_df['lan_code'] == 'spa').sum()\n",
    "count_por = (train_df['lan_code'] == 'por').sum()\n",
    "print(count_por, count_spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total ngrams is: 11789589 12344487\n",
      "The total ngrams is: 11494053 12025727\n",
      "The total ngrams is: 11198517 11706968\n",
      "The total ngrams is: 10902981 11388212\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    total_sump = sum(spaish_ngrams[i].values())\n",
    "    total_sumc= sum(czech_ngrams[i].values())\n",
    "\n",
    "    print(\"The total ngrams is:\", total_sump, total_sumc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaish_ngrams_normalised = [0, 0, 0, 0, 0]\n",
    "for i in range(1,5):\n",
    "    spaish_ngrams_normalised[i] = spaish_ngrams[i].copy()\n",
    "    sum_dict1 = sum(spaish_ngrams[i].values())\n",
    "    sum_dict2 = sum(czech_ngrams[i].values())\n",
    "\n",
    "    scaling_factor = sum_dict1 / sum_dict2\n",
    "\n",
    "    for key in spaish_ngrams[i]:\n",
    "        spaish_ngrams_normalised[i][key] /= scaling_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    spclassified_df = classify(test_df, i, spaish_ngrams_normalised[i], czech_ngrams[i])\n",
    "    spclassified_df.to_csv(f'spclassified_using_{i}_gram.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram & 0.7005732637213983 & 0.5213187128029484 \\\\ \n",
      "2-gram & 0.876277375334656 & 0.8761118418482295 \\\\ \n",
      "3-gram & 0.9511803643601784 & 0.9509943089325016 \\\\ \n",
      "4-gram & 0.9761608256581925 & 0.9761027257218019 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    spclassified_df = pd.read_csv(f'spclassified_without_normalisation_using_{i}_gram.csv')\n",
    "\n",
    "    true = (list(spclassified_df['lan_code']))\n",
    "    pred = (list(spclassified_df['predicted_lang']))\n",
    "\n",
    "\n",
    "   \n",
    "    print(f\"{i}-gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram & 0.6988153199542558 & 0.6986924870095198 \\\\ \n",
      "2-gram & 0.8721797790770908 & 0.869919387396304 \\\\ \n",
      "3-gram & 0.9468517655450945 & 0.9460325315483089 \\\\ \n",
      "4-gram & 0.9748565177203427 & 0.9748199565030539 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "precision_spa = [0,0,0,0,0]\n",
    "recall_spa = [0,0,0,0,0]\n",
    "precision_por = [0,0,0,0,0]\n",
    "recall_por = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    spclassified_df = pd.read_csv(f'spclassified_using_{i}_gram.csv')\n",
    "\n",
    "    true = (list(spclassified_df['lan_code']))\n",
    "    pred = (list(spclassified_df['predicted_lang']))\n",
    "    # TP = len(spclassified_df[(spclassified_df['lan_code'] == 'spa') & (spclassified_df['predicted_lang'] == 'spa')])\n",
    "    # TN = len(spclassified_df[(spclassified_df['lan_code'] != 'spa') & (spclassified_df['predicted_lang'] != 'spa')])\n",
    "    # FP = len(spclassified_df[(spclassified_df['lan_code'] != 'spa') & (spclassified_df['predicted_lang'] == 'spa')])\n",
    "    # FN = len(spclassified_df[(spclassified_df['lan_code'] == 'spa') & (spclassified_df['predicted_lang'] != 'spa')])\n",
    "\n",
    "    # # Calculate precision and recall\n",
    "    # precision_spa[i] = TP / (TP + FP) \n",
    "    # recall_spa[i] = TP / (TP + FN) \n",
    "\n",
    "    # print(TP,FP, TN,FN, precision_spa[i], recall_spa[i])\n",
    "    # TP = len(spclassified_df[(spclassified_df['lan_code'] == 'por') & (spclassified_df['predicted_lang'] == 'por')])\n",
    "    # TN = len(spclassified_df[(spclassified_df['lan_code'] != 'por') & (spclassified_df['predicted_lang'] != 'por')])\n",
    "    # FP = len(spclassified_df[(spclassified_df['lan_code'] != 'por') & (spclassified_df['predicted_lang'] == 'por')])\n",
    "    # FN = len(spclassified_df[(spclassified_df['lan_code'] == 'por') & (spclassified_df['predicted_lang'] != 'por')])\n",
    "\n",
    "    # precision_por[i] = TP / (TP + FP) \n",
    "    # recall_por[i] = TP / (TP + FN) \n",
    "    # print((TP+TN)/(TP+TN+FP+FN))\n",
    "    print(f\"{i}-gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n",
    "\n",
    "    # result[i] = spclassified_df[(spclassified_df['lan_code'] != spclassified_df['predicted_lang'])]\n",
    "    # compare(result[i],i, spaish_ngrams_normalised[i], czech_ngrams[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_zero(df, n, ngrams_spa, ngrams_por):\n",
    "    df['predicted_lang'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['spa_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "    df['por_count'] = ['not-predicted' for i in range(0, len(df['lan_code']))]\n",
    "\n",
    "    for index, data in df.iterrows():\n",
    "        lan = data['lan_code']\n",
    "        sentence = (data['sentence'])\n",
    "        count_spa = 0\n",
    "        zero_por = 0\n",
    "        zero_spa = 0\n",
    "\n",
    "        count_por = 0\n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            ngram = sentence[i:i + n]\n",
    "            if ngram not in ngrams_spa:\n",
    "                zero_por+=1\n",
    "                count_por += 1\n",
    "            elif ngram not in ngrams_por:\n",
    "                zero_spa+=1\n",
    "                count_spa += 1\n",
    "            elif ngrams_spa[ngram] < ngrams_por[ngram]:\n",
    "                count_por += 1\n",
    "            else:\n",
    "                count_spa += 1\n",
    "        if zero_por > 0:\n",
    "            df.at[index, 'predicted_lang'] = 'por'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "\n",
    "        elif zero_spa > 0:\n",
    "            \n",
    "            df.at[index, 'predicted_lang'] = 'spa'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "        elif count_spa >= count_por:\n",
    "            df.at[index, 'predicted_lang'] = 'spa'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "\n",
    "        else:\n",
    "            df.at[index, 'predicted_lang'] = 'por'\n",
    "            df.at[index, 'spa_count'] = count_spa\n",
    "            df.at[index, 'por_count'] = count_por\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    spclassified_df = classify_zero(test_df, i, spaish_ngrams_normalised[i], czech_ngrams[i])\n",
    "    spclassified_df.to_csv(f'spclassified_using_{i}_gram_zero_handled.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram & 0.6987838597721998 & 0.6986599294151353 \\\\ \n",
      "2-gram & 0.8931312694687771 & 0.8916418143696199 \\\\ \n",
      "3-gram & 0.9653095864938794 & 0.9653066274239129 \\\\ \n",
      "4-gram & 0.9732172228147676 & 0.9724041829997265 \\\\ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "result = [0,0,0,0,0]\n",
    "precision_scores = [0,0,0,0,0]\n",
    "for i in range(1,5):\n",
    "    spclassified_df = pd.read_csv(f'spclassified_using_{i}_gram_zero_handled.csv')\n",
    "\n",
    "    true = (list(spclassified_df['lan_code']))\n",
    "    pred = (list(spclassified_df['predicted_lang']))\n",
    "\n",
    "\n",
    "    print(f\"{i}-gram &\",precision_score(true, pred, average='weighted'), end=\" & \")\n",
    "    print(recall_score(true, pred, average='weighted'),end=\" \\\\\\\\ \\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
